{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adapted from rnaglib_first\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_supervised function from learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset was found and not overwritten\n",
      "Train Epoch: 1 [1/84 (1%)]\tLoss: 3.262544  Time: 0.73\n",
      "Train Epoch: 1 [21/84 (25%)]\tLoss: 1.723011  Time: 4.57\n",
      "Train Epoch: 1 [41/84 (49%)]\tLoss: 0.957033  Time: 9.99\n",
      "Train Epoch: 1 [61/84 (73%)]\tLoss: 0.760158  Time: 12.97\n",
      "Train Epoch: 1 [81/84 (96%)]\tLoss: 0.645697  Time: 18.61\n",
      "Train Epoch: 2 [1/84 (1%)]\tLoss: 0.699450  Time: 19.39\n",
      "Train Epoch: 2 [21/84 (25%)]\tLoss: 0.558471  Time: 24.70\n",
      "Train Epoch: 2 [41/84 (49%)]\tLoss: 0.528238  Time: 29.67\n",
      "Train Epoch: 2 [61/84 (73%)]\tLoss: 0.463922  Time: 34.21\n",
      "Train Epoch: 2 [81/84 (96%)]\tLoss: 0.463149  Time: 37.37\n",
      "Train Epoch: 3 [1/84 (1%)]\tLoss: 0.480446  Time: 37.62\n",
      "Train Epoch: 3 [21/84 (25%)]\tLoss: 0.367840  Time: 43.04\n",
      "Train Epoch: 3 [41/84 (49%)]\tLoss: 0.394295  Time: 46.00\n",
      "Train Epoch: 3 [61/84 (73%)]\tLoss: 0.358360  Time: 51.15\n",
      "Train Epoch: 3 [81/84 (96%)]\tLoss: 0.361634  Time: 55.39\n",
      "Train Epoch: 4 [1/84 (1%)]\tLoss: 0.360547  Time: 56.11\n",
      "Train Epoch: 4 [21/84 (25%)]\tLoss: 0.285045  Time: 62.30\n",
      "Train Epoch: 4 [41/84 (49%)]\tLoss: 0.331315  Time: 65.21\n",
      "Train Epoch: 4 [61/84 (73%)]\tLoss: 0.307029  Time: 70.26\n",
      "Train Epoch: 4 [81/84 (96%)]\tLoss: 0.331870  Time: 74.96\n",
      "Train Epoch: 5 [1/84 (1%)]\tLoss: 0.327473  Time: 75.89\n",
      "Train Epoch: 5 [21/84 (25%)]\tLoss: 0.302848  Time: 79.60\n",
      "Train Epoch: 5 [41/84 (49%)]\tLoss: 0.284440  Time: 84.30\n",
      "Train Epoch: 5 [61/84 (73%)]\tLoss: 0.288893  Time: 91.08\n",
      "Train Epoch: 5 [81/84 (96%)]\tLoss: 0.344019  Time: 94.56\n",
      "Train Epoch: 6 [1/84 (1%)]\tLoss: 0.306441  Time: 95.67\n",
      "Train Epoch: 6 [21/84 (25%)]\tLoss: 0.271887  Time: 100.40\n",
      "Train Epoch: 6 [41/84 (49%)]\tLoss: 0.299849  Time: 104.03\n",
      "Train Epoch: 6 [61/84 (73%)]\tLoss: 0.270416  Time: 109.55\n",
      "Train Epoch: 6 [81/84 (96%)]\tLoss: 0.284325  Time: 113.21\n",
      "Train Epoch: 7 [1/84 (1%)]\tLoss: 0.276494  Time: 113.64\n",
      "Train Epoch: 7 [21/84 (25%)]\tLoss: 0.268171  Time: 117.12\n",
      "Train Epoch: 7 [41/84 (49%)]\tLoss: 0.255221  Time: 121.39\n",
      "Train Epoch: 7 [61/84 (73%)]\tLoss: 0.257375  Time: 126.28\n",
      "Train Epoch: 7 [81/84 (96%)]\tLoss: 0.280025  Time: 131.15\n",
      "Train Epoch: 8 [1/84 (1%)]\tLoss: 0.275283  Time: 132.77\n",
      "Train Epoch: 8 [21/84 (25%)]\tLoss: 0.323432  Time: 138.17\n",
      "Train Epoch: 8 [41/84 (49%)]\tLoss: 0.250309  Time: 141.79\n",
      "Train Epoch: 8 [61/84 (73%)]\tLoss: 0.276569  Time: 146.01\n",
      "Train Epoch: 8 [81/84 (96%)]\tLoss: 0.261836  Time: 149.34\n",
      "Train Epoch: 9 [1/84 (1%)]\tLoss: 0.271841  Time: 150.92\n",
      "Train Epoch: 9 [21/84 (25%)]\tLoss: 0.223068  Time: 156.93\n",
      "Train Epoch: 9 [41/84 (49%)]\tLoss: 0.260160  Time: 161.73\n",
      "Train Epoch: 9 [61/84 (73%)]\tLoss: 0.247900  Time: 165.87\n",
      "Train Epoch: 9 [81/84 (96%)]\tLoss: 0.246266  Time: 169.16\n",
      "Train Epoch: 10 [1/84 (1%)]\tLoss: 0.217010  Time: 169.58\n",
      "Train Epoch: 10 [21/84 (25%)]\tLoss: 0.269694  Time: 174.06\n",
      "Train Epoch: 10 [41/84 (49%)]\tLoss: 0.238972  Time: 179.60\n",
      "Train Epoch: 10 [61/84 (73%)]\tLoss: 0.257833  Time: 183.54\n",
      "Train Epoch: 10 [81/84 (96%)]\tLoss: 0.241360  Time: 187.33\n",
      "Train Epoch: 11 [1/84 (1%)]\tLoss: 0.256916  Time: 188.68\n",
      "Train Epoch: 11 [21/84 (25%)]\tLoss: 0.243930  Time: 193.43\n",
      "Train Epoch: 11 [41/84 (49%)]\tLoss: 0.227433  Time: 197.79\n",
      "Train Epoch: 11 [61/84 (73%)]\tLoss: 0.233123  Time: 203.51\n",
      "Train Epoch: 11 [81/84 (96%)]\tLoss: 0.267710  Time: 206.92\n",
      "Train Epoch: 12 [1/84 (1%)]\tLoss: 0.269421  Time: 208.17\n",
      "Train Epoch: 12 [21/84 (25%)]\tLoss: 0.257013  Time: 211.38\n",
      "Train Epoch: 12 [41/84 (49%)]\tLoss: 0.232684  Time: 216.87\n",
      "Train Epoch: 12 [61/84 (73%)]\tLoss: 0.245535  Time: 221.27\n",
      "Train Epoch: 12 [81/84 (96%)]\tLoss: 0.204360  Time: 224.82\n",
      "Train Epoch: 13 [1/84 (1%)]\tLoss: 0.220160  Time: 225.83\n",
      "Train Epoch: 13 [21/84 (25%)]\tLoss: 0.251767  Time: 229.75\n",
      "Train Epoch: 13 [41/84 (49%)]\tLoss: 0.258738  Time: 235.00\n",
      "Train Epoch: 13 [61/84 (73%)]\tLoss: 0.260180  Time: 239.27\n",
      "Train Epoch: 13 [81/84 (96%)]\tLoss: 0.248169  Time: 243.69\n",
      "Train Epoch: 14 [1/84 (1%)]\tLoss: 0.267642  Time: 244.32\n",
      "Train Epoch: 14 [21/84 (25%)]\tLoss: 0.223777  Time: 251.14\n",
      "Train Epoch: 14 [41/84 (49%)]\tLoss: 0.249364  Time: 256.22\n",
      "Train Epoch: 14 [61/84 (73%)]\tLoss: 0.244116  Time: 259.75\n",
      "Train Epoch: 14 [81/84 (96%)]\tLoss: 0.198428  Time: 262.77\n",
      "Train Epoch: 15 [1/84 (1%)]\tLoss: 0.221320  Time: 263.11\n",
      "Train Epoch: 15 [21/84 (25%)]\tLoss: 0.231482  Time: 267.91\n",
      "Train Epoch: 15 [41/84 (49%)]\tLoss: 0.243091  Time: 270.71\n",
      "Train Epoch: 15 [61/84 (73%)]\tLoss: 0.219994  Time: 276.46\n",
      "Train Epoch: 15 [81/84 (96%)]\tLoss: 0.257151  Time: 281.12\n",
      "Train Epoch: 16 [1/84 (1%)]\tLoss: 0.227676  Time: 281.61\n",
      "Train Epoch: 16 [21/84 (25%)]\tLoss: 0.176546  Time: 285.89\n",
      "Train Epoch: 16 [41/84 (49%)]\tLoss: 0.258402  Time: 291.10\n",
      "Train Epoch: 16 [61/84 (73%)]\tLoss: 0.271479  Time: 294.51\n",
      "Train Epoch: 16 [81/84 (96%)]\tLoss: 0.235317  Time: 299.60\n",
      "Train Epoch: 17 [1/84 (1%)]\tLoss: 0.237026  Time: 300.13\n",
      "Train Epoch: 17 [21/84 (25%)]\tLoss: 0.217676  Time: 304.89\n",
      "Train Epoch: 17 [41/84 (49%)]\tLoss: 0.256344  Time: 309.60\n",
      "Train Epoch: 17 [61/84 (73%)]\tLoss: 0.228700  Time: 312.62\n",
      "Train Epoch: 17 [81/84 (96%)]\tLoss: 0.242061  Time: 317.00\n",
      "Train Epoch: 18 [1/84 (1%)]\tLoss: 0.238496  Time: 318.62\n",
      "Train Epoch: 18 [21/84 (25%)]\tLoss: 0.252040  Time: 323.69\n",
      "Train Epoch: 18 [41/84 (49%)]\tLoss: 0.251883  Time: 328.28\n",
      "Train Epoch: 18 [61/84 (73%)]\tLoss: 0.250165  Time: 333.49\n",
      "Train Epoch: 18 [81/84 (96%)]\tLoss: 0.222991  Time: 336.48\n",
      "Train Epoch: 19 [1/84 (1%)]\tLoss: 0.207765  Time: 337.05\n",
      "Train Epoch: 19 [21/84 (25%)]\tLoss: 0.250435  Time: 342.40\n",
      "Train Epoch: 19 [41/84 (49%)]\tLoss: 0.222524  Time: 347.49\n",
      "Train Epoch: 19 [61/84 (73%)]\tLoss: 0.226418  Time: 351.15\n",
      "Train Epoch: 19 [81/84 (96%)]\tLoss: 0.212203  Time: 355.20\n",
      "Train Epoch: 20 [1/84 (1%)]\tLoss: 0.254145  Time: 355.66\n",
      "Train Epoch: 20 [21/84 (25%)]\tLoss: 0.192451  Time: 359.04\n",
      "Train Epoch: 20 [41/84 (49%)]\tLoss: 0.205631  Time: 363.53\n",
      "Train Epoch: 20 [61/84 (73%)]\tLoss: 0.218868  Time: 367.01\n",
      "Train Epoch: 20 [81/84 (96%)]\tLoss: 0.234060  Time: 372.55\n",
      "Train Epoch: 21 [1/84 (1%)]\tLoss: 0.224509  Time: 373.80\n",
      "Train Epoch: 21 [21/84 (25%)]\tLoss: 0.226369  Time: 377.10\n",
      "Train Epoch: 21 [41/84 (49%)]\tLoss: 0.234973  Time: 381.42\n",
      "Train Epoch: 21 [61/84 (73%)]\tLoss: 0.212816  Time: 386.00\n",
      "Train Epoch: 21 [81/84 (96%)]\tLoss: 0.235557  Time: 391.82\n",
      "Train Epoch: 22 [1/84 (1%)]\tLoss: 0.236486  Time: 392.16\n",
      "Train Epoch: 22 [21/84 (25%)]\tLoss: 0.233830  Time: 395.69\n",
      "Train Epoch: 22 [41/84 (49%)]\tLoss: 0.231469  Time: 401.06\n",
      "Train Epoch: 22 [61/84 (73%)]\tLoss: 0.236709  Time: 404.80\n",
      "Train Epoch: 22 [81/84 (96%)]\tLoss: 0.233050  Time: 409.76\n",
      "Train Epoch: 23 [1/84 (1%)]\tLoss: 0.248601  Time: 411.29\n",
      "Train Epoch: 23 [21/84 (25%)]\tLoss: 0.230360  Time: 415.18\n",
      "Train Epoch: 23 [41/84 (49%)]\tLoss: 0.248914  Time: 420.73\n",
      "Train Epoch: 23 [61/84 (73%)]\tLoss: 0.206108  Time: 425.08\n",
      "Train Epoch: 23 [81/84 (96%)]\tLoss: 0.324184  Time: 429.37\n",
      "Train Epoch: 24 [1/84 (1%)]\tLoss: 0.255266  Time: 430.21\n",
      "Train Epoch: 24 [21/84 (25%)]\tLoss: 0.222023  Time: 434.90\n",
      "Train Epoch: 24 [41/84 (49%)]\tLoss: 0.240102  Time: 440.16\n",
      "Train Epoch: 24 [61/84 (73%)]\tLoss: 0.231092  Time: 443.36\n",
      "Train Epoch: 24 [81/84 (96%)]\tLoss: 0.209837  Time: 448.03\n",
      "Train Epoch: 25 [1/84 (1%)]\tLoss: 0.220687  Time: 448.60\n",
      "Train Epoch: 25 [21/84 (25%)]\tLoss: 0.258035  Time: 453.29\n",
      "Train Epoch: 25 [41/84 (49%)]\tLoss: 0.257048  Time: 457.66\n",
      "Train Epoch: 25 [61/84 (73%)]\tLoss: 0.174323  Time: 462.60\n",
      "Train Epoch: 25 [81/84 (96%)]\tLoss: 0.189117  Time: 477.16\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import torch\n",
    "\n",
    "from rnaglib.learning import models, learn\n",
    "from rnaglib.data_loading import rna_dataset, rna_loader\n",
    "from rnaglib.representations import GraphRepresentation\n",
    "\n",
    "\"\"\"\n",
    "This script just shows a first very basic example : learn binding protein preferences \n",
    "from the nucleotide types and the graph structure\n",
    "\n",
    "To do so, we choose our data, create a data loader around it, build a RGCN model and train it.\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Choose the data, features and targets to use and GET THE DATA GOING\n",
    "    node_features = ['nt_code']\n",
    "    node_target = ['binding_protein']\n",
    "    graph_rep = GraphRepresentation(framework='dgl')\n",
    "    supervised_dataset = rna_dataset.RNADataset(nt_features=node_features, nt_targets=node_target,\n",
    "                                                representations=[graph_rep])\n",
    "    train_loader, validation_loader, test_loader = rna_loader.get_loader(dataset=supervised_dataset)\n",
    "\n",
    "    # Define a model, we first embed our data in 10 dimensions, and then add one classification\n",
    "    input_dim, target_dim = supervised_dataset.input_dim, supervised_dataset.output_dim\n",
    "    embedder_model = models.Embedder(dims=[10, 10], infeatures_dim=input_dim)\n",
    "    classifier_model = models.Classifier(embedder=embedder_model, classif_dims=[target_dim])\n",
    "\n",
    "    # Finally get the training going\n",
    "    optimizer = torch.optim.Adam(classifier_model.parameters(), lr=0.001)\n",
    "    learn.train_supervised(model=classifier_model,\n",
    "                           optimizer=optimizer,\n",
    "                           train_loader=train_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
